

## Introducing IBM Power E1080

The Power E1080 is the newest addition to the IBM Power family, the industry's best-in-class server platform for security and reliability. The Power E1080 introduces the essential enterprise hybrid cloud platform, which is uniquely designed to help you securely and efficiently scale core operational and artificial intelligence (AI) applications anywhere in a hybrid cloud.

The Power E1080 simplifies end-to-end encryption and brings AI where your data is stored for faster insights. This configuration helps enable greater workload deployment flexibility and agility while accomplishing more work.

The Power E1080 can help you to realize the following benefits:

- Protect trust from core to cloud
- Protect data that is in-transit and at-rest with greatly simplified end-to-end encryption across hybrid cloud without affecting performance.
- Enjoy enterprise quality of service (QoS)
- The Power E1080 can detect, isolate, and recover from soft errors automatically in the hardware without taking an outage or relying on an operating system to manage the faults.
- Drive greater efficiency with sustainable and scalable compute
- The processor performance, massive system throughput, and memory capacity qualify the Power E1080 server to be the perfect workload consolidation platform. This performance leads to significant savings in floor space, energy consumption, and operational expenditure costs.

This chapter includes the following topics:

- 1.1, 'System overview' on page 2
- 1.2, 'System nodes' on page 7
- 1.3, 'System control unit' on page 10
- 1.4, 'Server specifications' on page 12
- 1.5, 'System features' on page 15
- 1.6, 'I/O drawers' on page 25
- 1.7, 'System racks' on page 30
- 1.8, 'Hardware Management Console overview' on page 39

## 1.1  System overview

The Power E1080, also referred to by its 9080-HEX machine type-model designation, represents the most powerful and scalable server in the IBM Power portfolio. It is composed of a combination of central electronic complex (CEC) enclosures that are called nodes (or system nodes ) and more units and drawers.

## 1.1.1  System nodes, processors, and memory

In this section, we provide a general overview of the system nodes, processors, and memory. For more information about the system nodes, see 1.2, 'System nodes' on page 7.

A system node is an enclosure that provides the connections and supporting electronics to connect the processor with the memory, internal disk, adapters, and the interconnects that are required for expansion. A combination of one, two, three, or four system nodes per server is supported.

Each system node provides four sockets for Power10 processor chips and 64 differential dual inline memory module (DDIMM) slots for Double Data Rate 5 (DDR5) or Double Data Rate 4 (DDR4) technology DIMMs.

Each socket holds one Power10 single-chip module (SCM). An SCM can contain 10, 12, or 15 Power10 processor cores. It also holds the extra infrastructure logic to provide electric power and data connectivity to the Power10 processor chip.

A 4-node Power E1080 server scales up to 16 processor sockets and 160, 192, or 240 cores, depending on the number of cores that is provided by the configured SCM type.

The processor configuration of a system node is defined by the selected processor feature. Each feature defines a set of four Power10 processors chips with the same core density (10, 12, or 15). All system nodes within a Power E1080 server must be configured with the same processor feature.

Each system node can support up to a maximum of 16 TB of system memory by using the largest available memory DIMM. A fully configured 4-node Power E1080 can support up to 64 TB of memory.

To provide internal boot capability, each system node enables up to four Non-Volatile Memory Express (NVMe) drive bays. More drive bays can be configured by using expansion drawers.

Each system node provides eight Peripheral Component Interconnect Express (PCIe) Gen 5 capable slots, with a maximum of 32 per Power E1080 server.

The system control unit (SCU) is required in all configurations. The SCU provides system hardware, firmware, and virtualization control through redundant Flexible Service Processors (FSPs). Only one SCU is required and supported for every Power E1080 server. For more information about the SCU, see 1.3, 'System control unit' on page 10.

For more information about the environmental and physical aspects of the server, see 1.4, 'Server specifications' on page 12.

## 1.1.2 Expansion drawers and storage enclosures

More PCIe slots can be added by using expansion drawers, and more disk capacity can be added to your system by using storage enclosures.

An expansion drawer provides more PCIe slots for I/O connectivity if needed. There are two versions of the PCIe expansion drawer: the original version supporting PCIe Gen 3 I/O slots 1 , and a newer version supporting PCIe Gen 4 I/O slots. There is no upgrade path from the Gen3 version to the Gen4 version, but you may mix the two I/O expansion drawers within a single system.

The I/O expansion drawer is a 19-inch PCIe 4U enclosure that provides up to 12 PCIe slots and connects to the system node with a pair of PCIe x16 to CXP converter cards (fanout adapters) that are housed in the system node. Each system node can support up to three Gen 4 I/O expansion drawers or four Gen 3 I/O expansion drawers, for a total of 48 PCIe Gen 3 slots or 36 PCIe Gen 4 slots. A fully configured Power E1080 can support a maximum of 16 Gen 3 I/O expansion drawers, providing a total of 192 PCIe Gen 3 slots or a maximum of 12 Gen 4 I.O expansion drawers for a total of 144 Gen 4 I/O slots.

An optional NVMe expansion capability is provided by the NED24 NVMe expansion drawer. The NED24 attaches to the system units by using the same fanout adapters that are used by the I/O expansion drawers and provides up to 24 NVMe U2 drive slots. Each NVMe drive can be individually assigned to its own partition, providing great flexibility for boot images and more data for each partition.

More serial-attached SCSI (SAS) storage can be implemented by using the EXP24SX SAS storage enclosure 2 , which provides twenty-four 2.5-inch small form factor (SFF) SAS bays. It supports up to 24 hot-swap hard disk drives (HDDs) or solid-state drives (SSDs) in only 2U rack units of space in a 19-inch rack. The EXP24SX is connected to the Power E1080 server by using SAS adapters that are plugged into PCIe slots either in the system nodes or in an I/O expansion drawer.

For more information about enclosures and drawers, see 1.6, 'I/O drawers' on page 25.

More storage can also be allocated externally by using Storage Network Connections through the appropriate adapters that are installed in the system PCIe slots. For more information about IBM storage products, see this web page.

## 1.1.3  Hardware at-a-glance

The Power E1080 server provides the following hardware components and characteristics:

- 10-, 12-, or 15-core Power10 processor chips that are packaged in an SCM per socket.
- One, two, three, or four system nodes with four Power10 processor sockets each.
- Redundant clocking in each system node.
- Up to 60 Power10 processor cores per system node and up to 240 per system.
- Up to 16 TB of memory per system node and up to 64 TB per system. Either DDR4 or DDR5 memory are supported.
- Eight PCIe Gen 5 slots per system node and a maximum of 32 PCIe Gen 5 slots per system.

- PCIe Gen 1, Gen 2, Gen 3, Gen 4, and Gen 5 adapters are supported in the system nodes.
- Up to three PCIe Gen 4 4U I/O expansion drawers per system node provide a maximum of 36 more PCIe Gen 4 slots or up to four PCIe Gen 3 expansion drawers for a maximum of 48 more PCIe Gen 3 slots.
- Up to 144 PCIe Gen 4 slots that use 12 PCI Gen 4 expansion drawers or 192 PCIe Gen 3 slots that use 16 PCIe Gen 3 I/O expansion drawers per system.
- Up to over 4,000 directly attached SAS HDDs or SSDs through EXP24SX SFF drawers.
- Up to 288 directly attached external NVMe drives that use 12 NED24 NVMe expansion drawers.
- SCU, which provides redundant FSPs and support for the operations panel, the system vital product data (VPD), and externally attached DVD.

The massive computational power, exceptional system capacity, and the unprecedented scalability of the Power E1080 server hardware are provided by unique enterprise class firmware and system software capabilities and features. The following important characteristics and features are offered by the IBM Power enterprise platform:

- Support for IBM AIX, IBM i, and Linux operating system environments, including support for Red Hat OpenShift Cloud Platform.
- An innovative dense math engine (DME) that is integrated in each Power10 processor core to accelerate AI-inferencing workloads.
- Optimized encryption units that are implemented in each Power10 processor core.
- Dedicated data compression engines that are provided by the Power10 processor technology.
- Hardware- and firmware-assisted and enforced security provide trusted boot and pervasive memory encryption support.
- Up to 1,000 virtual machines (VMs) or logical partitions (LPARs) per system.
- Dynamic LPAR (DLPAR) support to modify available processor and memory resources according to workload, without interruption of the business.
- Capacity on Demand (CoD) processor and memory options to help respond more rapidly and seamlessly to changing business requirements and growth.
- IBM Power Private Cloud Solution with Dynamic Capacity featuring Power Enterprise Pools 2.0 that supports unsurpassed enterprise flexibility for real-time workload balancing, system maintenance and operational expenditure cost management.

Table 1-1 compares important technical characteristics of the Power E1080 server with the Power E980 server, based on IBM Power9Â® processor-based technology.

Table 1-1   Comparing the Power E980 and the Power E1080 server

| Features                                                    | Power E980 server   | Power E1080 server             |
|-------------------------------------------------------------|---------------------|--------------------------------|
| Processor                                                   | Power9              | Power10                        |
| Processor package                                           | SCM                 | SCM                            |
| Cores per SCM                                               | 6, 8, 10, 11, 12    | 10, 12, 15                     |
| Number of cores per system                                  | Up to 192 cores     | Up to 240 cores                |
| Sockets per node                                            | 4                   | 4                              |
| System configuration options 1-, 2-, 3-, and 4-node systems |                     | 1-, 2-, 3-, and 4-node systems |

| Features                                             | Power E980 server                                           | Power E1080 server                                                                                                      |
|------------------------------------------------------|-------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|
| Maximum memory per node                              | 16 TB                                                       | 16 TB                                                                                                                   |
| Maximum memory per system                            | 64 TB                                                       | 64 TB                                                                                                                   |
| Maximum memory bandwidth per  node                   | 920 GBps                                                    | 1636 GBps                                                                                                               |
| Aggregated maximum memory  bandwidth per system      | 3680 GBps                                                   | 6544 GBps                                                                                                               |
| Pervasive memory encryption                          | No                                                          | Yes                                                                                                                     |
| PCIe slots per node                                  | Eight PCIe Gen 4 slots                                      | Eight PCIe Gen 5 slots                                                                                                  |
| I/O drawer expansion option                          | Yes                                                         | Yes                                                                                                                     |
| Acceleration ports                                   | Yes CAPI 2.0 & OpenCAPI 3.0 a                               | Yes OpenCAPI 3.0, 3.1                                                                                                   |
| PCIe hot-plug Support                                | Yes                                                         | Yes                                                                                                                     |
| I/O bandwidth per node                               | 545 GBps                                                    | 576 GBps                                                                                                                |
| Integrated USB                                       | USB 3.0                                                     | Not available                                                                                                           |
| Internal storage bays per node                       | Four NVMe PCIe Gen 3 bays b                                 | Four NVMe PCIe Gen 4 bays                                                                                               |
| Per lane bit rate between sockets                    | 25 Gbps                                                     | 32 Gbps                                                                                                                 |
| Reliability, availability, and  serviceability (RAS) | Symmetric multiprocessing  (SMP) c cable concurrent  repair | Non-active SMP cables with  concurrent maintenance  capability and time domain  reflectometry (TDR) d  fault  isolation |
| Secure and trusted boot                              | Yes                                                         | Yes                                                                                                                     |

- a. CAPI designates the coherent accelerator processor interface technology and OpenCAPI designates the open coherent accelerator processor interface technology. For more information about architectural specifications and the surrounding system, see this web page.
- b. NVMe designates the NVMe interface specification under the supervision of the NVM Express consortium: https://nvmexpress.org .
- c. Used to build monolithic servers out of multiple processor entities.
- d. Allows the server to actively detect faults in cables and locate discontinuities in a connector.

Figure 1-1 shows a 4-node Power E1080 server that is mounted in an IBM rack. Each system node is cooled by a set of five fans, which are arranged side by side in one row. The cooling assemblies show through the front door of the rack.

Figure 1-1   Power E1080 4-node server mounted in an S42 rack with a #ECRT door

<!-- image -->

## 1.1.4  System capacities and features

With any initial orders, the Power E1080 supports up to four system nodes. The maximum memory capacity that is supported in each node is 16 TB.

The maximum number of supported PCIe Gen 3 I/O expansion drawers is four per system node, which can be mixed with PCI Gen 4 expansion drawers (a maximum of three Gen 4 drawers are supported). Each I/O expansion drawer can be populated with two Fanout Modules. Each Fanout Module is connected to a system node through one PCIe x16 to CXP Converter Card.

In August 2024, IBM announced new memory features for the Power10 server line that use DDR5 technology. New memory features are available for the DDR5-based memory. The Power E1080 supports DDR5 and DDR4 DDIMMs in the same system, but all memory in each node must be the same type. The DDR5 DDIMMs provide increased memory bandwidth, which can result in improved performance of the system.

The following features are available:

- Maximum of four #EDN1 5U system node drawers
- Maximum of 16 TB of system memory per node drawer
- Maximum of 16 #EMX0 PCIe Gen 3 I/O expansion drawers or a maximum of 12 #ENZ0 PCIe Gen 4 I/O expansion drawers
- Maximum of 32 #EMXH PCIe Gen 3 6-slot Fanout Modules for PCIe Gen 3 expansion drawers or a maximum of 24 #ENFZ Fanout Modules for PCIe Gen 4 expansion drawers
- Maximum of 32 #EJ24 PCIe x16 to CXP Converter Cards

